{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code of using HKUST Azure OpenAI API with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you'll find the completed sample code. However, if you're looking for a more detailed understanding and want to follow along step by step with thorough explanations, we highly recommend you to read our article below:\n",
    "\n",
    "ğŸ‘‰ https://digitalhumanities.hkust.edu.hk/tutorials/how-to-use-hkust-azure-openai-api-key-with-python-with-sample-code-and-use-case-examples/\n",
    "\n",
    "The article provides comprehensive explanations and instructions that will help you grasp the underlying concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your OpenAI API key in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On 6 Nov 2023, [a new version of OpenAI](https://openai.com/blog/new-models-and-developer-products-announced-at-devday) is released. It is important to note that this version upgrade from the previous version 0.28.1 to version 1.x is a breaking change. The code for the OpenAI Python API library differs between these two versions. Below is the sample code of the respective code snippets for both version 0.28.1 and version 1.x.\n",
    "\n",
    "While the newly released GPT-4 Turbo model undoubtedly offers enhanced capabilities and power, we have chosen to utilize the gpt-35-turbo model for demonstration here. Rest assured, even though it is a slightly older version, it still delivers impressive performance and serves our demonstration needs.\n",
    "\n",
    "We encourage you to explore the potential of GPT-4 Turbo yourself once Azure OpenAI support it.\n",
    "\n",
    "+ Details of different models: https://platform.openai.com/docs/models\n",
    "+ The pricing details for different models per 1,000 tokens can be found here (default: USD$):\n",
    "https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI version 0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Parameters\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://hkust.azure-api.net\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = \"<your openai api key>\" #put your api key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to put your API key in a separate configuration file like `.env` for security reasons. This practice can separate your sensitive credentials from your codebase and ensure that they are not exposed if the code is shared or made public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use the following code if you would like to store your api key in the .env file\n",
    "# Content in .env file ---->  OPENAI_API_KEY=<your openai api key>\n",
    "\n",
    "# If you are using jupyterlab and couldnâ€™t locate the key in .env file. Here is an alternative way: https://gargankush.medium.com/storing-api-keys-as-environmental-variable-for-windows-linux-and-mac-and-accessing-it-through-974ba7c5109f\n",
    "\n",
    "'''\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('.env')\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def get_response(message, instruction):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine = 'gpt-35-turbo',\n",
    "        temperature = 1,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # print token usage\n",
    "    print(response.usage)\n",
    "    # return the response\n",
    "    return response.choices[0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt_tokens\": 26,\n",
      "  \"completion_tokens\": 39,\n",
      "  \"total_tokens\": 65\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Greetings! I am but a humble assistant, at your service. My tongue doth wag like the great bard Shakespeare, so speaketh thy commands and I shall bend my efforts to fulfill them.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"Who are you?\", \"You are an assistant that speaks like Shakespeare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI version 1.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please restart the notebook if you have installed another version of openai before. Run the install openai command in a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Parameters\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"https://hkust.azure-api.net\",\n",
    "  api_version = \"2023-05-15\",\n",
    "  api_key = \"<your openai api key>\" #put your api key here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def get_response(message, instruction):\n",
    "    response = client.chat.completions.create(\n",
    "\t\tmodel = 'gpt-35-turbo',\n",
    "        temperature = 1,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # print token usage\n",
    "    print(response.usage)\n",
    "    # return the response\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=26, prompt_tokens=26, total_tokens=52)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am but a humble assistant, good sir or lady, at your service. What may I assist thee with this fine day?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"Who are you?\", \"You are an assistant that speaks like Shakespeare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Parameters\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"https://hkust.azure-api.net\",\n",
    "  api_version = \"2023-05-15\",\n",
    "  api_key = \"<your openai api key>\" #put your api key here\n",
    ")\n",
    "# Function\n",
    "def get_response(message, instruction):\n",
    "    response = client.chat.completions.create(\n",
    "\t\tmodel = 'gpt-35-turbo',\n",
    "        temperature = 1,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # print the response\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "    # return the response\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text copied from https://library.hkust.edu.hk/events/conferences/ai-scholarly-commu-2023/\n",
    "\n",
    "Text = \"\"\"\n",
    "14 November 2023\n",
    "2:30 pm â€“ 4:00 pm\n",
    "Search Engine and Large Language Models â€“ Can they truly change the game?\n",
    "REGISTER\n",
    "Abstract\n",
    "Academic search engines are racing to incorporate the latest advancements brought about by Large Language models (LLMs) in terms of their ability to understand queries, extract information and directly generate answers. The first movers in this space were startup and challengers such as Elicit, Consensus.AI, Scite assistant, Scispace but they have recently been joined by established academic search engine provider like Elsevierâ€™s Scopus and Digital Scienceâ€™s Dimensions joining the fray with more to come.\n",
    "\n",
    "Using techniques like RAG (Retrieval augmented generation), this first wave of academic search engines hopes to combine search technology with generative AI by grounding the answers generated by LLMs using information context found by search engines, with the hope of reducing hallucinations. But is this enough?\n",
    "\n",
    "Join Aaron as he shares his experience testing and using these tools and his best guess on how these tools might develop in the future and their impact on research writing in the future.\n",
    "\n",
    "About the Speaker\n",
    "\n",
    "Aaron TayMr. Aaron Tay has been an academic librarian for over 10 years in Singapore and has worked in a variety of areas including library discovery, research support & bibliometrics. He is current Lead Data Services at the Singapore Management University Libraries and has been honoured for his contributions to the profession with a few awards including Library Association of Singapore (LAS) Professional Service Award, Congress of Southeast Asian Libraries (CONSAL) award (Silver) and Pacific Rim Research Library Alliance (PRRLA) , Karl Lo award.\n",
    "\n",
    "A past contributor to NMC horizon report (library edition), as well as a founding member of the Initiative for Open Abstracts, he has blended his interest in discovery and the evolving Scholarly ecosystem and has given talks on how AI/ML might change Scholarly communication. More recently, he has contributed to panels and given keynotes on the impact of AI and in particular large language models on academic libraries and institutions at conferences like CILIP, IATUL and more. He has been blogging at MusingsAboutLibrarianship.blogpost.com since 2009.\n",
    "\n",
    " \n",
    "\n",
    "15 November 2023\n",
    "4:00 pm â€“ 5:30 pm\n",
    "Saving Time and Sanity: Using active learning for systematic reviews and meta-analyses\n",
    "REGISTER\n",
    "Abstract\n",
    "Screening thousands of research papers for a systematic review or meta-analysis can be overwhelming. The reality is that there simply isnâ€™t enough time to read every single article.\n",
    "\n",
    "Join Prof. Dr. Rens van de Schoot as he introduces ASReview, a powerful free and open-source software for systematic reviewing, developed by his research team from Utrecht University. Rens will explain how active learning, a machine learning technique, can accelerate the step of manual screening process by saving up to 95% (!) of screening time. ASReview is more than just a tool; itâ€™s a vibrant community of researchers, users, and developers worldwide, contributing to its open-source mission, and Rens will explain how you can join the movement towards fast, open, and transparent systematic reviews.\n",
    "\n",
    "About the Speaker\n",
    "\n",
    "prof rens van de schoot profile photoProf. Dr. Rens van de Schoot works as a full professor for â€˜Statistics for Small Data Setsâ€™ at Utrecht University in the Netherlands and as an extra-ordinary professor at North-West University in South Africa. He is also the program director of the research master â€˜Methodology and Statistics for the Behavioural, Biomedical, and Social Sciencesâ€™. He is known for his many tutorials, checklists, and online (free) course materials in the areas of SEM and Bayesian statistics. Currently, his main research project is the community-driven and fully open-source project ASReview: AI-aided systematic reviewing using Active Learning. \n",
    "\n",
    " \n",
    "\n",
    "22 November 2023\n",
    "10:30 am â€“ 12:00 pm\n",
    "Generative AI for Translational Scholarly Communication\n",
    "REGISTER\n",
    "Abstract\n",
    "Many valuable insights embedded in scientific publications are siloed and rarely translated into results that can directly benefit humans. These research-to-practice gaps impede the diffusion of innovation, undermine evidence-based decision making, and contribute to the disconnect between science and the public. Generative AI systems trained on decades of digitized scholarly publications and other human-produced texts are now capable of generating (mostly) high-quality and (sometimes) trustworthy text, images, and media. Applied in the context of scholarly communication, Generative AI can quickly summarize research findings, generate visual diagrams of scientific content, and simplify technical jargon. In essence, Generative AI has the potential to help tailor language, format, tone, and examples to make research more accessible, understandable, engaging, and useful for different audiences.  \n",
    "\n",
    "In this talk, Iâ€™ll discuss some uses of Generative AI in these contexts as well as challenges towards realizing the potential of these models, e.g., how to effectively design generated translational science communication artifacts, incorporate human feedback in the process, and mitigate the generation of harmful, misleading, or false information. Scholarly communication is undergoing a major transformation with the emergence of these new tools. By using them safely, we can help bridge the research-to-practice gap and maximize the impacts of scientific discovery. \n",
    "\n",
    "About the Speaker\n",
    "\n",
    "Dr Lucy Lu Wang profile photoLucy Lu Wang is an Assistant Professor at the University of Washington Information School. Her research focuses on how to build better AI and NLP systems for extracting and understanding information from scientific texts; for example, can we create systems that leverage up-to-date literature to help us make better and more data-driven healthcare decisions, or design document understanding models that can improve the readability of scientific texts for people who are blind and low vision. Lucyâ€™s work on supplement interaction detection, gender trends in academic publishing, COVID-19 datasets, and document understanding has been featured in Geekwire, Boing Boing, Axios, VentureBeat, and the New York Times. Prior to joining the UW, she was a Young Investigator at the Allen Institute for AI, and she received her PhD in Biomedical Informatics and Medical Education from the University of Washington.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1:\n",
      "Name: Aaron Tay\n",
      "University: Singapore Management University\n",
      "Specialist: Academic librarian with a focus on library discovery, research support, and bibliometrics.\n",
      "Presentation Title: Search Engine and Large Language Models â€“ Can they truly change the game?\n",
      "\n",
      "Speaker 2:\n",
      "Name: Prof. Dr. Rens van de Schoot\n",
      "University: Utrecht University (Netherlands) and North-West University (South Africa)\n",
      "Specialist: Full Professor for â€˜Statistics for Small Data Setsâ€™ and Program Director for the research master â€˜Methodology and Statistics for the Behavioural, Biomedical, and Social Sciencesâ€™\n",
      "Presentation Title: Saving Time and Sanity: Using active learning for systematic reviews and meta-analyses\n",
      "\n",
      "Speaker 3:\n",
      "Name: Dr. Lucy Lu Wang\n",
      "University: University of Washington Information School\n",
      "Specialist: Assistant Professor in AI and NLP, with a focus on extracting and understanding information from scientific texts\n",
      "Presentation Title: Generative AI for Translational Scholarly Communication\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Speaker 1:\\nName: Aaron Tay\\nUniversity: Singapore Management University\\nSpecialist: Academic librarian with a focus on library discovery, research support, and bibliometrics.\\nPresentation Title: Search Engine and Large Language Models â€“ Can they truly change the game?\\n\\nSpeaker 2:\\nName: Prof. Dr. Rens van de Schoot\\nUniversity: Utrecht University (Netherlands) and North-West University (South Africa)\\nSpecialist: Full Professor for â€˜Statistics for Small Data Setsâ€™ and Program Director for the research master â€˜Methodology and Statistics for the Behavioural, Biomedical, and Social Sciencesâ€™\\nPresentation Title: Saving Time and Sanity: Using active learning for systematic reviews and meta-analyses\\n\\nSpeaker 3:\\nName: Dr. Lucy Lu Wang\\nUniversity: University of Washington Information School\\nSpecialist: Assistant Professor in AI and NLP, with a focus on extracting and understanding information from scientific texts\\nPresentation Title: Generative AI for Translational Scholarly Communication'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"You are a helpful assistant.\"\n",
    "\n",
    "get_response(f\"\"\"\n",
    "             Please extract each of the speaker name, their corresponding university, their specialist (within 20 words), and presentation title. \n",
    "             Text:{Text}\n",
    "            \"\"\", \n",
    "            instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Name,University,Specialist,Presentation Title\n",
      "Aaron Tay,Singapore Management University Libraries,Academic search engines and bibliometrics,\"Search Engine and Large Language Models â€“ Can they truly change the game?\"\n",
      "Prof. Dr. Rens van de Schoot,Utrecht University,Statistics for Small Data Sets,\"Saving Time and Sanity: Using active learning for systematic reviews and meta-analyses\"\n",
      "Dr. Lucy Lu Wang,University of Washington Information School,Artificial Intelligence and Natural Language Processing,\"Generative AI for Translational Scholarly Communication\"\n"
     ]
    }
   ],
   "source": [
    "instruction = \"You are a helpful assistant.\"\n",
    "\n",
    "csv_result = get_response(f\"\"\"\n",
    "             Please extract each of the speaker name, their corresponding university, their specialist (within 20 words), and presentation title. Please return the results in csv format.\n",
    "             Text:{Text}\n",
    "            \"\"\", \n",
    "            instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speaker Name,University,Specialist,Presentation Title\\nAaron Tay,Singapore Management University Libraries,Academic search engines and bibliometrics,\"Search Engine and Large Language Models â€“ Can they truly change the game?\"\\nProf. Dr. Rens van de Schoot,Utrecht University,Statistics for Small Data Sets,\"Saving Time and Sanity: Using active learning for systematic reviews and meta-analyses\"\\nDr. Lucy Lu Wang,University of Washington Information School,Artificial Intelligence and Natural Language Processing,\"Generative AI for Translational Scholarly Communication\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A csv file is created and saved in the same folder of this notebook.\n"
     ]
    }
   ],
   "source": [
    "# save the result to csv file\n",
    "import csv  \n",
    "with open('outputfile_NER-example.csv', 'w', encoding='UTF8') as f:\n",
    "    f.write(csv_result)    \n",
    "    print(\"A csv file is created and saved in the same folder of this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classified by sentiment: Positive, Negative, Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really enjoyed the movie. It was fantastic!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service at the restaurant was terrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The customer support was very helpful and resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The shop was okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The product I bought was of poor quality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0      I really enjoyed the movie. It was fantastic!\n",
       "1        The service at the restaurant was terrible.\n",
       "2  The customer support was very helpful and resp...\n",
       "3                                 The shop was okay.\n",
       "4          The product I bought was of poor quality."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample DataFrame\n",
    "sampledata = {\n",
    "    'Text': [\"I really enjoyed the movie. It was fantastic!\", \n",
    "             \"The service at the restaurant was terrible.\", \n",
    "             \"The customer support was very helpful and responsive.\",\n",
    "             \"The shop was okay.\",\n",
    "             \"The product I bought was of poor quality.\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=sampledata)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n",
      "positive\n",
      "neutral\n",
      "negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really enjoyed the movie. It was fantastic!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service at the restaurant was terrible.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The customer support was very helpful and resp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The shop was okay.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The product I bought was of poor quality.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment\n",
       "0      I really enjoyed the movie. It was fantastic!  positive\n",
       "1        The service at the restaurant was terrible.  negative\n",
       "2  The customer support was very helpful and resp...  positive\n",
       "3                                 The shop was okay.   neutral\n",
       "4          The product I bought was of poor quality.  negative"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the instruction for sentiment analysis\n",
    "instruction = \"Please analyze the sentiment of the following text. Only use the exact wording 'positive', 'negative', or 'neutral' in your response. Do not say any other irrelevant things, no punctuation.\"\n",
    "\n",
    "# Create a new column for sentiment\n",
    "df['Sentiment'] = \"\"\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the text from the 'Text' column\n",
    "    text = row['Text']\n",
    "    \n",
    "    # Get the sentiment response using the get_response function\n",
    "    sentiment = get_response(text, instruction)\n",
    "    \n",
    "    # Store the sentiment result in the 'Sentiment' column\n",
    "    df.at[index, 'Sentiment'] = sentiment\n",
    "\n",
    "# display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classified by categories: Facilities, Services, Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The best place to stay in UST.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our library is the best!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the ground floor of the library, i thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our library provide information and resources ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æœå‹™è‰¯å¥½ã€ç’°å¢ƒéå¸¸èˆ’é©ï¼Œå¯ä»¥è®“æˆ‘å°ˆå¿ƒæº«ç¿’ã€ è³‡æºè±å¯Œã€è·å“¡äº¦å¾ˆå‹å–„ï¼Œæ¨‚æ„è©³ç´°å›ç­”æˆ‘çš„å• é¡Œï¼Œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>å›¾ä¹¦é¦†æœ‰å¾ˆå¥½çš„ç¯å¢ƒï¼Œä¹Ÿä¼šæä¾›å„ç§æ´»åŠ¨å’Œè®²åº§å¸®åŠ©æˆ‘ä»¬ç†Ÿæ‚‰ä½¿ç”¨å›¾ä¹¦é¦†çš„èµ„æºï¼Œå–œæ¬¢æˆ‘ä»¬çš„å›¾ä¹¦é¦†ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0                     The best place to stay in UST.\n",
       "1                           Our library is the best!\n",
       "2  I love the ground floor of the library, i thin...\n",
       "3  Our library provide information and resources ...\n",
       "4  æœå‹™è‰¯å¥½ã€ç’°å¢ƒéå¸¸èˆ’é©ï¼Œå¯ä»¥è®“æˆ‘å°ˆå¿ƒæº«ç¿’ã€ è³‡æºè±å¯Œã€è·å“¡äº¦å¾ˆå‹å–„ï¼Œæ¨‚æ„è©³ç´°å›ç­”æˆ‘çš„å• é¡Œï¼Œ...\n",
       "5      å›¾ä¹¦é¦†æœ‰å¾ˆå¥½çš„ç¯å¢ƒï¼Œä¹Ÿä¼šæä¾›å„ç§æ´»åŠ¨å’Œè®²åº§å¸®åŠ©æˆ‘ä»¬ç†Ÿæ‚‰ä½¿ç”¨å›¾ä¹¦é¦†çš„èµ„æºï¼Œå–œæ¬¢æˆ‘ä»¬çš„å›¾ä¹¦é¦†ã€‚"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the comments that the library received in LibQUAL 2019 as sample data https://library.hkust.edu.hk/about-us/user-engagement/libqual2019/\n",
    "sampledata = {\n",
    "    'Text': [\"The best place to stay in UST.\",\n",
    "            \"Our library is the best!\",\n",
    "            \"I love the ground floor of the library, i think especially in the morning it is so peaceful and calm.\",\n",
    "            \"Our library provide information and resources for us, including materials and many classes about how to use them. I really thanks staffs of library. And further I hope that our library could provide more chance and resource of 3D printer and I really love it.\",\n",
    "            \"æœå‹™è‰¯å¥½ã€ç’°å¢ƒéå¸¸èˆ’é©ï¼Œå¯ä»¥è®“æˆ‘å°ˆå¿ƒæº«ç¿’ã€ è³‡æºè±å¯Œã€è·å“¡äº¦å¾ˆå‹å–„ï¼Œæ¨‚æ„è©³ç´°å›ç­”æˆ‘çš„å• é¡Œï¼Œæ´»å‹•ç¨®é¡ç¹å¤šï¼Œå¯ä»¥è®“æˆ‘æ‰¾åˆ°èˆˆè¶£ï¼Œåˆèƒ½å­¸ç¿’ æ–°çš„æ±è¥¿ã€‚\",\n",
    "            \"å›¾ä¹¦é¦†æœ‰å¾ˆå¥½çš„ç¯å¢ƒï¼Œä¹Ÿä¼šæä¾›å„ç§æ´»åŠ¨å’Œè®²åº§å¸®åŠ©æˆ‘ä»¬ç†Ÿæ‚‰ä½¿ç”¨å›¾ä¹¦é¦†çš„èµ„æºï¼Œå–œæ¬¢æˆ‘ä»¬çš„å›¾ä¹¦é¦†ã€‚\"]\n",
    "            }\n",
    "\n",
    "libqual2019 = pd.DataFrame(data=sampledata)\n",
    "libqual2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Cannot be classified.\n",
      "positive\n",
      "Cannot be classified.\n",
      "positive\n",
      "Facilities\n",
      "positive\n",
      "Services, Resources.\n",
      "positive\n",
      "Services, Facilities, Resources, Activities\n",
      "positive\n",
      "Services, Activities.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The best place to stay in UST.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Cannot be classified.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our library is the best!</td>\n",
       "      <td>positive</td>\n",
       "      <td>Cannot be classified.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the ground floor of the library, i thin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our library provide information and resources ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Services, Resources.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æœå‹™è‰¯å¥½ã€ç’°å¢ƒéå¸¸èˆ’é©ï¼Œå¯ä»¥è®“æˆ‘å°ˆå¿ƒæº«ç¿’ã€ è³‡æºè±å¯Œã€è·å“¡äº¦å¾ˆå‹å–„ï¼Œæ¨‚æ„è©³ç´°å›ç­”æˆ‘çš„å• é¡Œï¼Œ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Services, Facilities, Resources, Activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>å›¾ä¹¦é¦†æœ‰å¾ˆå¥½çš„ç¯å¢ƒï¼Œä¹Ÿä¼šæä¾›å„ç§æ´»åŠ¨å’Œè®²åº§å¸®åŠ©æˆ‘ä»¬ç†Ÿæ‚‰ä½¿ç”¨å›¾ä¹¦é¦†çš„èµ„æºï¼Œå–œæ¬¢æˆ‘ä»¬çš„å›¾ä¹¦é¦†ã€‚</td>\n",
       "      <td>positive</td>\n",
       "      <td>Services, Activities.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment  \\\n",
       "0                     The best place to stay in UST.  positive   \n",
       "1                           Our library is the best!  positive   \n",
       "2  I love the ground floor of the library, i thin...  positive   \n",
       "3  Our library provide information and resources ...  positive   \n",
       "4  æœå‹™è‰¯å¥½ã€ç’°å¢ƒéå¸¸èˆ’é©ï¼Œå¯ä»¥è®“æˆ‘å°ˆå¿ƒæº«ç¿’ã€ è³‡æºè±å¯Œã€è·å“¡äº¦å¾ˆå‹å–„ï¼Œæ¨‚æ„è©³ç´°å›ç­”æˆ‘çš„å• é¡Œï¼Œ...  positive   \n",
       "5      å›¾ä¹¦é¦†æœ‰å¾ˆå¥½çš„ç¯å¢ƒï¼Œä¹Ÿä¼šæä¾›å„ç§æ´»åŠ¨å’Œè®²åº§å¸®åŠ©æˆ‘ä»¬ç†Ÿæ‚‰ä½¿ç”¨å›¾ä¹¦é¦†çš„èµ„æºï¼Œå–œæ¬¢æˆ‘ä»¬çš„å›¾ä¹¦é¦†ã€‚  positive   \n",
       "\n",
       "                                      Category  \n",
       "0                        Cannot be classified.  \n",
       "1                        Cannot be classified.  \n",
       "2                                   Facilities  \n",
       "3                         Services, Resources.  \n",
       "4  Services, Facilities, Resources, Activities  \n",
       "5                        Services, Activities.  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the instruction for sentiment analysis\n",
    "instruction1 = \"Please analyze the sentiment of the following text. Only use the exact wording 'positive', 'negative', or 'neutral' in your response. All lowercase. Do not say any other irrelevant things. Do not include full stop in your response.\"\n",
    "\n",
    "# Define the instruction for category classification\n",
    "instruction2 = \"\"\"\n",
    "Please classify the following text into these categories (exact wordings) 'Services', 'Facilities', 'Resources', 'Activities' or 'Cannot be classified' in your response. Do not say any other words. Remember only use these 4 categories in your response: 'Services', 'Facilities', 'Resources', 'Activities', 'Cannot be classified'. Use 'Cannot be classified' only when no categories can be assigned to the text.\n",
    "\"\"\"\n",
    "\n",
    "# Create new columns for sentiment and category\n",
    "libqual2019['Sentiment'] = \"\"\n",
    "libqual2019['Category'] = \"\"\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the text from the 'Text' column\n",
    "    text = row['Text']\n",
    "    \n",
    "    # Get the response using the get_response function\n",
    "    sentiment = get_response(text, instruction1)\n",
    "    category = get_response(text, instruction2)\n",
    "    \n",
    "    # Store the result in the column\n",
    "    libqual2019.at[index, 'Sentiment'] = sentiment\n",
    "    libqual2019.at[index, 'Category'] = category\n",
    "\n",
    "# display the updated DataFrame\n",
    "libqual2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Translation\n",
    "Example: classical Chinese (æ–‡è¨€æ–‡) to vernacular Chinese (ç™½è©±æ–‡)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç™½è©±æ–‡ï¼š\n",
      "ç¾åœ¨æœ‰ä¸€å¡ŠåœŸåœ°ï¼Œé•·åäº”æ­¥ï¼Œå¯¬åå…­æ­¥ï¼Œå•é€™å¡ŠåœŸåœ°é¢ç©æ˜¯å¤šå°‘ï¼Ÿå›ç­”æ˜¯ä¸€ç•ã€‚\n",
      "\n",
      "é‚„æœ‰ä¸€å¡ŠåœŸåœ°ï¼Œé•·åäºŒæ­¥ï¼Œå¯¬åå››æ­¥ï¼Œå•é€™å¡ŠåœŸåœ°é¢ç©æ˜¯å¤šå°‘ï¼Ÿå›ç­”æ˜¯ä¸€ç™¾å…­åå…«æ­¥ã€‚\n",
      "\n",
      "æ±‚åœŸåœ°é¢ç©çš„æ–¹æ³•å«åšã€Œæ–¹ç”°è¡“ã€ã€‚å¯ä»¥ç”¨é•·å’Œå¯¬çš„æ­¥æ•¸ç›¸ä¹˜ï¼Œå¾—åˆ°åœŸåœ°çš„é¢ç©ã€‚å¦‚æœè¦æ›ç®—æˆç•ï¼Œè¦ç”¨æ¯ç•äºŒç™¾å››åæ­¥çš„é¢ç©å»é™¤ï¼Œå¾—åˆ°çš„æ•¸å­—å°±æ˜¯ç•æ•¸ã€‚ä¸€ç™¾ç•ç­‰æ–¼ä¸€é ƒã€‚\n"
     ]
    }
   ],
   "source": [
    "instruction = \"You are an expert in Mathematics and proficient in classical Chinese.\"\n",
    "Text = \"\"\"\n",
    "ä»Šæœ‰ç”°å»£åäº”æ­¥ï¼Œå¾åå…­æ­¥ã€‚å•ç‚ºç”°å¹¾ä½•ï¼Ÿ\t\t\n",
    "ç­”æ›°ï¼šä¸€ç•ã€‚\n",
    "æ–¹ç”°ï¼šåˆæœ‰ç”°å»£åäºŒæ­¥ï¼Œå¾åå››æ­¥ã€‚å•ç‚ºç”°å¹¾ä½•ï¼Ÿ\t\t\n",
    "ç­”æ›°ï¼šä¸€ç™¾å…­åå…«æ­¥ã€‚\t\t\n",
    "æ–¹ç”°è¡“æ›°ï¼šå»£å¾æ­¥æ•¸ç›¸ä¹˜å¾—ç©æ­¥ã€‚ä»¥ç•æ³•äºŒç™¾å››åæ­¥é™¤ä¹‹ï¼Œå³ç•æ•¸ã€‚ç™¾ç•ç‚ºä¸€é ƒã€‚\n",
    "\"\"\"\n",
    "\n",
    "get_response(f\"\"\"\n",
    "             è«‹æŠŠä»¥ä¸‹æ–‡è¨€æ–‡ç¿»è­¯æˆç™½è©±æ–‡ï¼š\n",
    "             æ–‡è¨€æ–‡:{Text}\n",
    "            \"\"\", \n",
    "            instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦–å…ˆï¼Œå°‡é¡Œç›®ç¿»è­¯æˆç¾ä»£ä¸­æ–‡ï¼šç¾åœ¨æœ‰ä¸€å¡Šç”°ï¼Œé•·15æ­¥ï¼Œå¯¬16æ­¥ï¼Œå•é€™å¡Šç”°æ˜¯å¤šå¤§é¢ç©ï¼Ÿ ç­”æ¡ˆæ˜¯ä¸€ç•ã€‚æ¥è‘—ï¼Œåˆæœ‰ä¸€å¡Šé•·12æ­¥ï¼Œå¯¬14æ­¥çš„ç”°ï¼Œå•é€™å¡Šç”°æ˜¯å¤šå¤§é¢ç©ï¼Ÿç­”æ¡ˆæ˜¯ä¸€ç™¾å…­åå…«æ­¥ã€‚\n",
      "\n",
      "æ ¹æ“šæ–¹ç”°è¡“ï¼Œç”°çš„é¢ç©å¯ä»¥é€šéå»£ï¼ˆé•·ï¼‰å’Œå¾ï¼ˆå¯¬ï¼‰çš„æ­¥æ•¸ç›¸ä¹˜è€Œå¾—ã€‚å› æ­¤ï¼Œç¬¬ä¸€å¡Šç”°çš„é¢ç©ç‚ºï¼š\n",
      "\n",
      "é•· Ã— å¯¬ = 15 Ã— 16 = 240 æ­¥\n",
      "\n",
      "æ ¹æ“šä¸€ç•ç­‰æ–¼äºŒç™¾å››åæ­¥çš„æ¨™æº–ï¼Œé€™å¡Šç”°çš„é¢ç©ç‚ºä¸€ç•ã€‚\n",
      "\n",
      "åŒæ¨£åœ°ï¼Œç¬¬äºŒå¡Šç”°çš„é¢ç©ç‚ºï¼š\n",
      "\n",
      "é•· Ã— å¯¬ = 12 Ã— 14 = 168 æ­¥\n",
      "\n",
      "å› æ­¤ï¼Œç¬¬äºŒå¡Šç”°çš„é¢ç©ç‚ºä¸€ç™¾å…­åå…«æ­¥ã€‚\n",
      "\n",
      "æœ€å¾Œï¼Œæ–¹ç”°è¡“é‚„æåˆ°ï¼Œå°‡ç”°åœ°çš„é¢ç©é™¤ä»¥äºŒç™¾å››åæ­¥ï¼Œå°±å¯ä»¥å¾—åˆ°ç”°çš„ç•æ•¸ã€‚ä¸€é ƒç­‰æ–¼ä¸€ç™¾ç•ã€‚\n"
     ]
    }
   ],
   "source": [
    "instruction = \"You are an expert in Mathematics and proficient in classical Chinese.\"\n",
    "Text = \"\"\"\n",
    "ä»Šæœ‰ç”°å»£åäº”æ­¥ï¼Œå¾åå…­æ­¥ã€‚å•ç‚ºç”°å¹¾ä½•ï¼Ÿ\t\t\n",
    "ç­”æ›°ï¼šä¸€ç•ã€‚\n",
    "æ–¹ç”°ï¼šåˆæœ‰ç”°å»£åäºŒæ­¥ï¼Œå¾åå››æ­¥ã€‚å•ç‚ºç”°å¹¾ä½•ï¼Ÿ\t\t\n",
    "ç­”æ›°ï¼šä¸€ç™¾å…­åå…«æ­¥ã€‚\t\t\n",
    "æ–¹ç”°è¡“æ›°ï¼šå»£å¾æ­¥æ•¸ç›¸ä¹˜å¾—ç©æ­¥ã€‚ä»¥ç•æ³•äºŒç™¾å››åæ­¥é™¤ä¹‹ï¼Œå³ç•æ•¸ã€‚ç™¾ç•ç‚ºä¸€é ƒã€‚\n",
    "\"\"\"\n",
    "\n",
    "get_response(f\"\"\"\n",
    "             è«‹ä»¥æ•¸å­¸å…¬å¼é€æ­¥è§£é‡‹ä»¥ä¸‹æ–‡è¨€æ–‡çš„å…§å®¹:\n",
    "             æ–‡è¨€æ–‡:{Text}\n",
    "            \"\"\", \n",
    "            instruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
